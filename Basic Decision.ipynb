{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# prepare data\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "#processing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "#Quality control and metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "#Models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection,linear_model, preprocessing, ensemble, metrics, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm\n",
    "\n",
    "\n",
    "#scaller\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "#encoder\n",
    "import category_encoders as ce\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "\n",
    "#fill nan\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "## visualise\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var190</th>\n",
       "      <th>Var191</th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>...</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NESt0G8EIb</td>\n",
       "      <td>AERks4l</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>0LaQ</td>\n",
       "      <td>UaKK0yW</td>\n",
       "      <td>I1sFbv_0IT</td>\n",
       "      <td>...</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>vr93T2a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>xwM2aC7IdeMC0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P1WvyxLp3Z</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>YFAj</td>\n",
       "      <td>Bnunsla</td>\n",
       "      <td>o64y9zI</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>6hQ9lNX</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FoxgUHSK8h</td>\n",
       "      <td>LrdZy8QqgUfkVShG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>TyGl</td>\n",
       "      <td>fhk21Ss</td>\n",
       "      <td>nQUveAzAF7</td>\n",
       "      <td>...</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vNEvyxLp3Z</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>0Xwj</td>\n",
       "      <td>uoZk2Zj</td>\n",
       "      <td>LWyxgtXeJL</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>e4lqvY0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4e7gUH7IEC</td>\n",
       "      <td>RO12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>vSNn</td>\n",
       "      <td>kugYdIL</td>\n",
       "      <td>ZIXKpoNpqq</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>MAz3HNj</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var190 Var191      Var192            Var193 Var194 Var195 Var196 Var197  \\\n",
       "ID                                                                            \n",
       "0      NaN    NaN  NESt0G8EIb           AERks4l    NaN   taul   1K8T   0LaQ   \n",
       "1      NaN    NaN  P1WvyxLp3Z           2Knk1KF    NaN   taul   1K8T   YFAj   \n",
       "2      NaN    NaN  FoxgUHSK8h  LrdZy8QqgUfkVShG    NaN   taul   1K8T   TyGl   \n",
       "3      NaN    NaN  vNEvyxLp3Z              RO12    NaN   taul   1K8T   0Xwj   \n",
       "4      NaN    NaN  4e7gUH7IEC              RO12    NaN   taul   1K8T   vSNn   \n",
       "\n",
       "     Var198      Var199  ...   Var221   Var222      Var223 Var224 Var225  \\\n",
       "ID                       ...                                               \n",
       "0   UaKK0yW  I1sFbv_0IT  ...  Al6ZaUT  vr93T2a  LM8l689qOp    NaN    NaN   \n",
       "1   Bnunsla     o64y9zI  ...     oslk  6hQ9lNX  LM8l689qOp    NaN   ELof   \n",
       "2   fhk21Ss  nQUveAzAF7  ...     zCkv  catzS2D  LM8l689qOp    NaN    NaN   \n",
       "3   uoZk2Zj  LWyxgtXeJL  ...     oslk  e4lqvY0  LM8l689qOp    NaN    NaN   \n",
       "4   kugYdIL  ZIXKpoNpqq  ...     oslk  MAz3HNj  LM8l689qOp    NaN    NaN   \n",
       "\n",
       "   Var226   Var227         Var228 Var229  Var230  \n",
       "ID                                                \n",
       "0    fKCe  02N6s8f  xwM2aC7IdeMC0    NaN     NaN  \n",
       "1    xb3V     RAYp        55YFVY9   mj86     NaN  \n",
       "2    FSa2     ZI9m  ib5G6X1eUxUn6   mj86     NaN  \n",
       "3    xb3V     RAYp  F2FyR07IdsN7I    NaN     NaN  \n",
       "4    WqMG     RAYp  F2FyR07IdsN7I    NaN     NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('/Users/nikli/Documents/git_reps/Data/orange_small_churn_test_data.csv',index_col = 'ID')\n",
    "train_data = pd.read_csv('/Users/nikli/Documents/git_reps/Data/orange_small_churn_train_data.csv',index_col = 'ID')\n",
    "train_labels=train_data['labels'].fillna(-1)\n",
    "train_data['labels']=train_data['labels'].fillna(-1)\n",
    "train_data=train_data.drop('labels', axis=1)\n",
    "train_data.loc[:,'Var190':].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План:\n",
    "Построить базовые модели на основе преобразования датасета различными способами и замерить качество базовых моделей:\n",
    "<!-- - <a href='#fillna'> 1. Закодировать категориальные признаки,заменить пропуски </a>\n",
    "- <a href='#first_result'> 2. Сделать просто фит предикт - записать результат модели на сабмите </a>\n",
    "- <a href='#prepare_dataset'> 3. Сделать анализ датафрейма, удалить признаки, которые слабо коррелируют - записать результат модели на сабмите </a>\n",
    "- <a href='#prepare_dataset'> 6. Сделать кросс валидацию & подбор параметров модели - записать результат модели на сабмите  </a>\n",
    "- <a href='#prepare_dataset'> 7. Сделать вывод про лучший скор </a>\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удалим столбцы тестовой выборки,в которых нет никакой информации : set(column) = {Nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Способ поиска пропусков\n",
      "[nan]\n",
      "Так мы будем находить массив уникальные значения ,которые являются рпопусками или нет\n",
      "[True]\n",
      "Проверим на наличие пропусков\n",
      "True\n",
      "Мы должны добавить ещё одну проверку , на длинну массива\n",
      "[False, True, False, False, False, False, False, False, False, False, False, False, False]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('Способ поиска пропусков')\n",
    "print(train_data['Var79'].unique())\n",
    "print('Так мы будем находить массив уникальные значения ,которые являются рпопусками или нет')\n",
    "print([np.isnan(nan) for nan in train_data['Var79'].unique()])\n",
    "print('Проверим на наличие пропусков')\n",
    "print(any([np.isnan(nan) for nan in train_data['Var79'].unique()]))\n",
    "array=[np.isnan(nan) for nan in train_data['Var78'].unique()]\n",
    "print('Мы должны добавить ещё одну проверку , на длинну массива')\n",
    "print(array)\n",
    "print(False in array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удалим неинформативные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def undersampling(data, labels,col_to_label):\n",
    "\n",
    "    data['Labels']=labels\n",
    "    dataChurn = data[data['Labels'] == 1]\n",
    "    \n",
    "    dataNoChurn = data[data['Labels'] == -1]\n",
    "    \n",
    "    countFirst = len(dataChurn)\n",
    "    dataChurn = dataChurn.append(dataNoChurn.iloc[:countFirst,:])\n",
    "    dataChurn = shuffle(dataChurn)\n",
    "    return dataChurn.iloc[:,:col_to_label], dataChurn.iloc[:,col_to_label:]\n",
    "train_data , train_labels = undersampling(train_data, train_labels, 230)\n",
    "\n",
    "# def dropUninformative(data):\n",
    "#     df=data.copy()\n",
    "#     imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "#     df.loc[:,:] = imputer.fit_transform(df.loc[:,:])\n",
    "#     return data[df.loc[:,  (df != df.iloc[0]).any()].columns]\n",
    "\n",
    "def dropUninformative(data):\n",
    "    data=data.copy()\n",
    "    df = pd.DataFrame([])\n",
    "    for i in range(data.shape[1]):\n",
    "        if len(data.iloc[:,i].unique())>1:\n",
    "            df[\"Var\"+str(i+1)] = data.iloc[:,i]\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data=dropUninformative(train_data)\n",
    "test_data=test_data[train_data.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var100</th>\n",
       "      <th>Var101</th>\n",
       "      <th>Var102</th>\n",
       "      <th>Var103</th>\n",
       "      <th>Var104</th>\n",
       "      <th>Var105</th>\n",
       "      <th>Var106</th>\n",
       "      <th>Var107</th>\n",
       "      <th>...</th>\n",
       "      <th>Var90</th>\n",
       "      <th>Var91</th>\n",
       "      <th>Var92</th>\n",
       "      <th>Var93</th>\n",
       "      <th>Var94</th>\n",
       "      <th>Var95</th>\n",
       "      <th>Var96</th>\n",
       "      <th>Var97</th>\n",
       "      <th>Var98</th>\n",
       "      <th>Var99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12717</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15965</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53031.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16067</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106083.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2754 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var1  Var10  Var100  Var101  Var102  Var103  Var104  Var105  Var106  \\\n",
       "ID                                                                           \n",
       "12717   0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "12410   0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "779     0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "15965   0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "476     0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...     ...    ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "7925    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "559     0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "16067   0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "994     0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1216    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       Var107  ...  Var90  Var91  Var92  Var93     Var94  Var95  Var96  Var97  \\\n",
       "ID             ...                                                              \n",
       "12717     0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "12410     0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "779       0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "15965     0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "476       0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "...       ...  ...    ...    ...    ...    ...       ...    ...    ...    ...   \n",
       "7925      0.0  ...    0.0    0.0    0.0    0.0   53031.0    0.0    0.0    0.0   \n",
       "559       0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "16067     0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "994       0.0  ...    0.0    0.0    0.0    0.0       0.0    0.0    0.0    0.0   \n",
       "1216      0.0  ...    0.0    0.0    0.0    0.0  106083.0    0.0    0.0    0.0   \n",
       "\n",
       "       Var98  Var99  \n",
       "ID                   \n",
       "12717    0.0    0.0  \n",
       "12410    0.0    0.0  \n",
       "779      0.0    0.0  \n",
       "15965    0.0    0.0  \n",
       "476      0.0    0.0  \n",
       "...      ...    ...  \n",
       "7925     0.0    0.0  \n",
       "559      0.0    0.0  \n",
       "16067    0.0    0.0  \n",
       "994      0.0    0.0  \n",
       "1216     0.0    0.0  \n",
       "\n",
       "[2754 rows x 174 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Теперь мы можем тестировать способы замены пропусков в числах:\n",
    "### Теперь мы можем тестировать способы кодирования данных:\n",
    "def fill_numeric(train_data,  strategy=\"mean\"):\n",
    "    train_data=train_data.copy()\n",
    "    if strategy==\"mean\":\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "\n",
    "    if strategy=='median':\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "    if strategy=='most_frequent':\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    if strategy=='0':\n",
    "        train_data=train_data.fillna(0)\n",
    "        return train_data\n",
    "\n",
    "    train_data.loc[:,:] = imputer.fit_transform(train_data.loc[:,:])\n",
    "    return train_data\n",
    "\n",
    "\n",
    "fill_numeric(train_data[train_data.columns.difference(train_data.loc[:,'Var191':'Var229'].columns)],  strategy=\"mean\")\n",
    "fill_numeric(train_data[train_data.columns.difference(train_data.loc[:,'Var191':'Var229'].columns)],  strategy=\"median\")\n",
    "fill_numeric(train_data[train_data.columns.difference(train_data.loc[:,'Var191':'Var229'].columns)],  strategy=\"most_frequent\")\n",
    "fill_numeric(train_data[train_data.columns.difference(train_data.loc[:,'Var191':'Var229'].columns)],  strategy=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var191</th>\n",
       "      <th>Var192</th>\n",
       "      <th>Var193</th>\n",
       "      <th>Var194</th>\n",
       "      <th>Var195</th>\n",
       "      <th>Var196</th>\n",
       "      <th>Var197</th>\n",
       "      <th>Var198</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var200</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12717</th>\n",
       "      <td>No_info</td>\n",
       "      <td>CEat0G8rTN</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>wOc1</td>\n",
       "      <td>fayYfhR</td>\n",
       "      <td>YQcPlrpk3ptPA</td>\n",
       "      <td>UsLnYKt</td>\n",
       "      <td>...</td>\n",
       "      <td>KbkKEj0</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>QqVuch3</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>No_info</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>Zy3gnGM</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>No_info</td>\n",
       "      <td>4e7gUH7IEC</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>0Xwj</td>\n",
       "      <td>ho_bxgw</td>\n",
       "      <td>TP5nuUTLjIwLuWf8pjH</td>\n",
       "      <td>UsLnYKt</td>\n",
       "      <td>...</td>\n",
       "      <td>AvcOVQC</td>\n",
       "      <td>oslk</td>\n",
       "      <td>r757j0h</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>No_info</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>w_Ub</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>No_info</td>\n",
       "      <td>a4vPe2fHUn</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>PGNs</td>\n",
       "      <td>XPJvY8M</td>\n",
       "      <td>1lFJzqR</td>\n",
       "      <td>hAV35Zc</td>\n",
       "      <td>...</td>\n",
       "      <td>nNRvOIl</td>\n",
       "      <td>oslk</td>\n",
       "      <td>VVjqhZX</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>No_info</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15965</th>\n",
       "      <td>No_info</td>\n",
       "      <td>J9Vr4RQZiT</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>kNzO</td>\n",
       "      <td>FJD_9E2</td>\n",
       "      <td>o64y9zI</td>\n",
       "      <td>CJCmkSe</td>\n",
       "      <td>...</td>\n",
       "      <td>ylCK4WV</td>\n",
       "      <td>oslk</td>\n",
       "      <td>kiBRltV</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>No_info</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>Zy3gnGM</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>No_info</td>\n",
       "      <td>AUUt0GoOh3</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>7gSz</td>\n",
       "      <td>tAqBboK</td>\n",
       "      <td>nQUq7hGe64</td>\n",
       "      <td>W0mqXyJ</td>\n",
       "      <td>...</td>\n",
       "      <td>B0LABPr</td>\n",
       "      <td>oslk</td>\n",
       "      <td>UP3EVaf</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>No_info</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7925</th>\n",
       "      <td>r__I</td>\n",
       "      <td>gOyrjIs7u7</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ssAy</td>\n",
       "      <td>6KF0k8W</td>\n",
       "      <td>9g4oaYjoL0</td>\n",
       "      <td>2rMgZjZ</td>\n",
       "      <td>...</td>\n",
       "      <td>ot6oLzk</td>\n",
       "      <td>oslk</td>\n",
       "      <td>IIvC99a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>PM2D</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>r__I</td>\n",
       "      <td>crIt0Go8Lb</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>wGW5</td>\n",
       "      <td>jCepSrJ</td>\n",
       "      <td>J_sb4dmQwP</td>\n",
       "      <td>2rMgZjZ</td>\n",
       "      <td>...</td>\n",
       "      <td>Oy_RPEi</td>\n",
       "      <td>oslk</td>\n",
       "      <td>FS4qjNq</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16067</th>\n",
       "      <td>r__I</td>\n",
       "      <td>P1WvyxLp3Z</td>\n",
       "      <td>2Knk1KF</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ssAy</td>\n",
       "      <td>8Nsn57c</td>\n",
       "      <td>TP5upuTLjIwLuWf8pjH</td>\n",
       "      <td>ZkcHC5O</td>\n",
       "      <td>...</td>\n",
       "      <td>07m8iqZ</td>\n",
       "      <td>oslk</td>\n",
       "      <td>VjJAgOW</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>xG3x</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>r__I</td>\n",
       "      <td>9rAq9at_88</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>4fje</td>\n",
       "      <td>IfKEQZy</td>\n",
       "      <td>I1sfFVhsuI</td>\n",
       "      <td>ZkcHC5O</td>\n",
       "      <td>...</td>\n",
       "      <td>bDIDFjT</td>\n",
       "      <td>oslk</td>\n",
       "      <td>gsLzpoz</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>xG3x</td>\n",
       "      <td>me1d</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>r__I</td>\n",
       "      <td>dRaTmBfHUn</td>\n",
       "      <td>RO12</td>\n",
       "      <td>SEuy</td>\n",
       "      <td>taul</td>\n",
       "      <td>1K8T</td>\n",
       "      <td>ssAy</td>\n",
       "      <td>CNDAHbp</td>\n",
       "      <td>VKm8_AwS48</td>\n",
       "      <td>p_UbGd4</td>\n",
       "      <td>...</td>\n",
       "      <td>QMamIK9</td>\n",
       "      <td>oslk</td>\n",
       "      <td>nwM52bd</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>4n2X</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2754 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Var191      Var192   Var193 Var194 Var195 Var196 Var197   Var198  \\\n",
       "ID                                                                         \n",
       "12717  No_info  CEat0G8rTN  2Knk1KF   SEuy   taul   1K8T   wOc1  fayYfhR   \n",
       "12410  No_info  4e7gUH7IEC     RO12   SEuy   taul   1K8T   0Xwj  ho_bxgw   \n",
       "779    No_info  a4vPe2fHUn     RO12   SEuy   taul   1K8T   PGNs  XPJvY8M   \n",
       "15965  No_info  J9Vr4RQZiT  2Knk1KF   SEuy   taul   1K8T   kNzO  FJD_9E2   \n",
       "476    No_info  AUUt0GoOh3     RO12   SEuy   taul   1K8T   7gSz  tAqBboK   \n",
       "...        ...         ...      ...    ...    ...    ...    ...      ...   \n",
       "7925      r__I  gOyrjIs7u7     RO12   SEuy   taul   1K8T   ssAy  6KF0k8W   \n",
       "559       r__I  crIt0Go8Lb     RO12   SEuy   taul   1K8T   wGW5  jCepSrJ   \n",
       "16067     r__I  P1WvyxLp3Z  2Knk1KF   SEuy   taul   1K8T   ssAy  8Nsn57c   \n",
       "994       r__I  9rAq9at_88     RO12   SEuy   taul   1K8T   4fje  IfKEQZy   \n",
       "1216      r__I  dRaTmBfHUn     RO12   SEuy   taul   1K8T   ssAy  CNDAHbp   \n",
       "\n",
       "                    Var199   Var200  ...   Var220 Var221   Var222      Var223  \\\n",
       "ID                                   ...                                        \n",
       "12717        YQcPlrpk3ptPA  UsLnYKt  ...  KbkKEj0   zCkv  QqVuch3  LM8l689qOp   \n",
       "12410  TP5nuUTLjIwLuWf8pjH  UsLnYKt  ...  AvcOVQC   oslk  r757j0h  jySVZNlOJy   \n",
       "779                1lFJzqR  hAV35Zc  ...  nNRvOIl   oslk  VVjqhZX  jySVZNlOJy   \n",
       "15965              o64y9zI  CJCmkSe  ...  ylCK4WV   oslk  kiBRltV  jySVZNlOJy   \n",
       "476             nQUq7hGe64  W0mqXyJ  ...  B0LABPr   oslk  UP3EVaf  LM8l689qOp   \n",
       "...                    ...      ...  ...      ...    ...      ...         ...   \n",
       "7925            9g4oaYjoL0  2rMgZjZ  ...  ot6oLzk   oslk  IIvC99a  LM8l689qOp   \n",
       "559             J_sb4dmQwP  2rMgZjZ  ...  Oy_RPEi   oslk  FS4qjNq  LM8l689qOp   \n",
       "16067  TP5upuTLjIwLuWf8pjH  ZkcHC5O  ...  07m8iqZ   oslk  VjJAgOW  LM8l689qOp   \n",
       "994             I1sfFVhsuI  ZkcHC5O  ...  bDIDFjT   oslk  gsLzpoz  LM8l689qOp   \n",
       "1216            VKm8_AwS48  p_UbGd4  ...  QMamIK9   oslk  nwM52bd  LM8l689qOp   \n",
       "\n",
       "        Var224 Var225 Var226   Var227         Var228 Var229  \n",
       "ID                                                           \n",
       "12717  No_info   kG3k   fKCe  02N6s8f        Zy3gnGM   am7c  \n",
       "12410  No_info   kG3k   w_Ub     RAYp  F2FyR07IdsN7I   am7c  \n",
       "779    No_info   kG3k   FSa2     RAYp  F2FyR07IdsN7I   mj86  \n",
       "15965  No_info   kG3k   FSa2     6fzt        Zy3gnGM   mj86  \n",
       "476    No_info   kG3k   Qu4f     RAYp  F2FyR07IdsN7I   am7c  \n",
       "...        ...    ...    ...      ...            ...    ...  \n",
       "7925      4n2X   ELof   PM2D     RAYp  F2FyR07IdsN7I   am7c  \n",
       "559       4n2X   ELof   Qu4f     RAYp  F2FyR07IdsN7I   am7c  \n",
       "16067     4n2X   xG3x   xb3V     RAYp        55YFVY9   mj86  \n",
       "994       4n2X   xG3x   me1d     RAYp  F2FyR07IdsN7I   mj86  \n",
       "1216      4n2X   ELof   Qu4f     RAYp  F2FyR07IdsN7I   am7c  \n",
       "\n",
       "[2754 rows x 38 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Теперь мы можем тестировать способы замены пропусков в числах:\n",
    "### Теперь мы можем тестировать способы кодирования данных:\n",
    "def fill_cat(train_data,  strategy=\"most_frequent\"):\n",
    "    train_data=train_data.copy()\n",
    "    \n",
    "    if strategy=='most_frequent':\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "        train_data.loc[:,:] = imputer.fit_transform(train_data.loc[:,:])\n",
    "        #print('most frequent')\n",
    "        \n",
    "    if strategy=='No_info':\n",
    "        train_data=train_data.fillna('No_info')\n",
    "        #print('Done No_info!')\n",
    "    \n",
    "    if strategy=='bfill':\n",
    "        train_data=train_data.fillna(method='bfill')\n",
    "        train_data=train_data.fillna('No_info')\n",
    "        #print('Done method bfill!')\n",
    "        \n",
    "    if strategy=='pad':\n",
    "        train_data=train_data.fillna(method='pad')\n",
    "        train_data=train_data.fillna('No_info')\n",
    "        #print('Done method pad!')    \n",
    "\n",
    "\n",
    "    return train_data\n",
    "\n",
    "fill_cat(train_data[train_data.columns.difference(train_data.loc[:,'Var1':'Var190'].columns)],  strategy=\"most_frequent\")\n",
    "fill_cat(train_data[train_data.columns.difference(train_data.loc[:,'Var1':'Var190'].columns)],  strategy=\"No_info\")\n",
    "fill_cat(train_data[train_data.columns.difference(train_data.loc[:,'Var1':'Var190'].columns)],  strategy=\"bfill\")\n",
    "fill_cat(train_data[train_data.columns.difference(train_data.loc[:,'Var1':'Var190'].columns)],  strategy=\"pad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Закодируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cat_coding(train_data, train_labels,  method, test_data):\n",
    "    train_data=train_data.copy()\n",
    "    train_data['labels'] = train_labels\n",
    "    cols=train_data.loc[:,'Var191':'Var229'].columns\n",
    "    \n",
    "    if method=='frequency':\n",
    "        for col in cols:\n",
    "            freq_encode = train_data.groupby(col).size() / train_data.shape[0]\n",
    "            train_data.loc[:, col] = train_data[col].map(freq_encode)\n",
    "            test_data.loc[:, col] = test_data[col].map(freq_encode)\n",
    "        #train_data= train_data\n",
    "        \n",
    "    elif method=='mean':\n",
    "        for col in cols:\n",
    "            mean_encode = train_data.groupby(col)['labels'].mean() # Считаем среднее значение таргета группиря по нашему столбцу\n",
    "            train_data.loc[:, col] = train_data[col].map(mean_encode)\n",
    "            test_data.loc[:, col] = test_data[col].map(mean_encode)\n",
    "        \n",
    "    elif method=='smoothed':\n",
    "        for col in cols:\n",
    "            mean = train_data['labels'].mean() # Находим среднее значение\n",
    "            agg = train_data.groupby(col)['labels'].agg(['count', 'mean']) # Считаем среднее значение и число повторов значения столбца\n",
    "            counts = agg['count']\n",
    "            means = agg['mean']\n",
    "            weight = 100\n",
    "            smooth = (counts * means + weight * mean) / (counts + weight)\n",
    "            train_data.loc[:, col] = train_data[col].map(smooth)\n",
    "            test_data.loc[:, col] = test_data[col].map(smooth)\n",
    "            \n",
    "            \n",
    "    elif method=='WOE':#Weight of Evidence encoding | считаем ln отношения вероятностей принадлежности к классам\n",
    "        WOEE_encoder = ce.WOEEncoder()\n",
    "        print(train_data.isna().sum().sum())\n",
    "        print(np.any(np.isnan(train_data)))\n",
    "        train_data.loc[:,'Var191':'Var229'] = WOEE_encoder.fit_transform(train_data.loc[:,'Var191':'Var229'],\n",
    "                                                                         train_data['labels'])\n",
    "        test_data.loc[:,'Var191':'Var229'] = WOEE_encoder.transform(test_data.loc[:,'Var191':'Var229'])\n",
    "    elif method=='leave_one_out':#Leave-one-out encoding | Считает среднее значение таргета для случая, когда пример удален из дата-сета.\n",
    "        LOOE_encoder = ce.LeaveOneOutEncoder()\n",
    "        train_data.loc[:,'Var191':'Var229'] = LOOE_encoder.fit_transform(train_data.loc[:,'Var191':'Var229'],\n",
    "                                                                         train_data['labels'])\n",
    "        test_data.loc[:,'Var191':'Var229'] = LOOE_encoder.transform(test_data.loc[:,'Var191':'Var229'])\n",
    "\n",
    "    elif method=='сatboost':\n",
    "        CBE_encoder = CatBoostEncoder()\n",
    "        train_data.loc[:,'Var191':'Var229'] = CBE_encoder.fit_transform(train_data.loc[:,'Var191':'Var229'],\n",
    "                                                                         train_data['labels'])\n",
    "        test_data.loc[:,'Var191':'Var229'] = CBE_encoder.transform(test_data.loc[:,'Var191':'Var229'])\n",
    "\n",
    "    pass\n",
    "    del train_data['labels']\n",
    "    return train_data, test_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_append (model : str, cat_cod : str, fill_num : str, fill_cat : str,  x_train, x_test, y_train, y_test):\n",
    "    if model=='CatBoost':\n",
    "        clf=CatBoostClassifier(iterations=90)\n",
    "        clf.fit(x_train, y_train, verbose=False)\n",
    "        model_info = {\n",
    "                 'Model' : model, \n",
    "                 'Cat_coding' : cat_cod,\n",
    "                 'Num_fill' : fill_num,\n",
    "                 'Cat_fill' : fill_cat,\n",
    "                 'Train auc score' : round(roc_auc_score(y_train, clf.predict_proba(x_train)[:, 1]), 3), \n",
    "                 'Train f1 score' : round(f1_score(y_train, clf.predict(x_train)), 3),\n",
    "                 'Test auc score' : round(roc_auc_score(y_test, clf.predict_proba(x_test)[:, 1]), 3), \n",
    "                 'Test f1 score' : round(f1_score(y_test, clf.predict(x_test)), 3)\n",
    "                 }\n",
    "        return model_info\n",
    "    elif model=='XGBoost':\n",
    "        clf=XGBClassifier()\n",
    "    elif model=='Logistsic Regression':\n",
    "        clf=LogisticRegression()\n",
    "    elif model=='LightGBM':\n",
    "        clf=lightgbm.LGBMClassifier()\n",
    "    elif model=='Decision Tree':\n",
    "        clf=DecisionTreeClassifier()\n",
    "    elif model=='Random Forest':\n",
    "        clf=ensemble.RandomForestClassifier()\n",
    "        \n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    model_info = {\n",
    "                 'Model' : model, \n",
    "                 'Cat_coding' : cat_cod,\n",
    "                 'Num_fill' : fill_num,\n",
    "                 'Cat_fill' : fill_cat,\n",
    "                 'Train auc score' : round(roc_auc_score(y_train, clf.predict_proba(x_train)[:, 1]), 3), \n",
    "                 'Train f1 score' : round(f1_score(y_train, clf.predict(x_train)), 3),\n",
    "                 'Test auc score' : round(roc_auc_score(y_test, clf.predict_proba(x_test)[:, 1]), 3), \n",
    "                 'Test f1 score' : round(f1_score(y_test, clf.predict(x_test)), 3)\n",
    "                 }\n",
    "    return model_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_fill_methods=['most_frequent', 'No_info', 'bfill', 'pad']\n",
    "num_fill_methods=['mean', 'median', 'most_frequent', '0']\n",
    "cat_code_methods=['frequency', 'mean', 'smoothed', 'leave_one_out', 'сatboost']\n",
    "models=['CatBoost', 'XGBoost', 'Logistsic Regression', 'LightGBM', 'Decision Tree', 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cat_coding</th>\n",
       "      <th>Num_fill</th>\n",
       "      <th>Cat_fill</th>\n",
       "      <th>Train auc score</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test auc score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Cat_coding, Num_fill, Cat_fill, Train auc score, Train f1 score, Test auc score, Test f1 score]\n",
       "Index: []"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model' : [], 'Cat_coding':[], 'Num_fill':[], 'Cat_fill':[], 'Train auc score' : [],\n",
    "                       'Train f1 score' : [], 'Test auc score' : [], 'Test f1 score' : []})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for cat_meth in cat_fill_methods:\n",
    "    for num_meth in num_fill_methods:\n",
    "        for cat_cod_meth in cat_code_methods:\n",
    "            for model in models:\n",
    "                train_data_exp = train_data.copy()\n",
    "\n",
    "                train_data_exp[train_data_exp.columns.difference(train_data_exp.loc[:,'Var191':'Var229'].columns)]=fill_numeric(\n",
    "                    train_data_exp[train_data_exp.columns.difference(train_data_exp.loc[:,'Var191':'Var229'].columns)],\n",
    "                    strategy=num_meth)\n",
    "                \n",
    "                train_data_exp[train_data_exp.columns.difference(train_data_exp.loc[:,'Var1':'Var190'].columns)]=fill_cat(\n",
    "                    train_data_exp[train_data_exp.columns.difference(train_data_exp.loc[:,'Var1':'Var190'].columns)],\n",
    "                    strategy=cat_meth)\n",
    "                \n",
    "                y =train_data_exp['labels']\n",
    "                del train_data_exp['labels']\n",
    "                X = train_data_exp\n",
    "                x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345678)\n",
    "\n",
    "                x_train, x_test=cat_coding(x_train, y_train, cat_cod_meth, x_test)\n",
    "                x_test=x_test.fillna(method='pad')\n",
    "                \n",
    "                #print(model,cat_cod_meth,num_meth,cat_meth)\n",
    "                \n",
    "                info = results_append (model=model, cat_cod=cat_cod_meth, fill_num=num_meth,\n",
    "                                fill_cat=cat_meth, x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n",
    "                result=result.append(info ,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Было немного проблемматично записать все результаты:\n",
    "1. Изначально запись глобального датафрейма была из функции 'results_append', что для норм кода не ок\n",
    "2. Неправильно кодировал категориальные признаки. Я кодировал весь датасет в разбивке по таргету. Из-за этого были сформированны линейно-зависимые с таргетом признаки.\n",
    "3. Обучающая и тестовая выборка не всегда одинаковые, если какого-то значения не было в обучающей выборке, то в тестовой это значение заменится на Nan. Такой пропуск был лишь 1 , заполнил его предыдущим значением.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cat_coding</th>\n",
       "      <th>Num_fill</th>\n",
       "      <th>Cat_fill</th>\n",
       "      <th>Train auc score</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test auc score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>leave_one_out</td>\n",
       "      <td>mean</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>mean</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>mean</td>\n",
       "      <td>pad</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>mean</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>mean</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>mean</td>\n",
       "      <td>bfill</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>median</td>\n",
       "      <td>pad</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>0</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>0</td>\n",
       "      <td>bfill</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>median</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>smoothed</td>\n",
       "      <td>median</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>frequency</td>\n",
       "      <td>median</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>mean</td>\n",
       "      <td>pad</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>0</td>\n",
       "      <td>No_info</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>pad</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>leave_one_out</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>leave_one_out</td>\n",
       "      <td>0</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>сatboost</td>\n",
       "      <td>0</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model     Cat_coding       Num_fill       Cat_fill  Train auc score  \\\n",
       "18   CatBoost  leave_one_out           mean  most_frequent            0.955   \n",
       "24   CatBoost       сatboost           mean  most_frequent            0.955   \n",
       "384  CatBoost       сatboost           mean            pad            0.964   \n",
       "144  CatBoost       сatboost           mean        No_info            0.964   \n",
       "145   XGBoost       сatboost           mean        No_info            0.911   \n",
       "264  CatBoost       сatboost           mean          bfill            0.965   \n",
       "205   XGBoost       сatboost  most_frequent        No_info            0.906   \n",
       "414  CatBoost       сatboost         median            pad            0.960   \n",
       "234  CatBoost       сatboost              0        No_info            0.974   \n",
       "354  CatBoost       сatboost              0          bfill            0.972   \n",
       "175   XGBoost       сatboost         median        No_info            0.908   \n",
       "162  CatBoost       smoothed         median        No_info            0.962   \n",
       "150  CatBoost      frequency         median        No_info            0.961   \n",
       "385   XGBoost       сatboost           mean            pad            0.899   \n",
       "235   XGBoost       сatboost              0        No_info            0.908   \n",
       "445   XGBoost       сatboost  most_frequent            pad            0.891   \n",
       "78   CatBoost  leave_one_out  most_frequent  most_frequent            0.959   \n",
       "84   CatBoost       сatboost  most_frequent  most_frequent            0.959   \n",
       "108  CatBoost  leave_one_out              0  most_frequent            0.964   \n",
       "114  CatBoost       сatboost              0  most_frequent            0.964   \n",
       "\n",
       "     Train f1 score  Test auc score  Test f1 score  \n",
       "18            0.879           0.721          0.685  \n",
       "24            0.879           0.721          0.685  \n",
       "384           0.899           0.720          0.697  \n",
       "144           0.898           0.720          0.679  \n",
       "145           0.823           0.719          0.679  \n",
       "264           0.902           0.718          0.698  \n",
       "205           0.826           0.717          0.692  \n",
       "414           0.893           0.716          0.681  \n",
       "234           0.914           0.714          0.673  \n",
       "354           0.913           0.713          0.687  \n",
       "175           0.828           0.713          0.676  \n",
       "162           0.893           0.712          0.669  \n",
       "150           0.891           0.712          0.657  \n",
       "385           0.824           0.710          0.688  \n",
       "235           0.821           0.709          0.677  \n",
       "445           0.802           0.709          0.673  \n",
       "78            0.892           0.709          0.664  \n",
       "84            0.892           0.709          0.664  \n",
       "108           0.898           0.709          0.659  \n",
       "114           0.898           0.709          0.659  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by=['Test auc score','Test f1 score'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test auc score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.669888</td>\n",
       "      <td>0.656263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.663788</td>\n",
       "      <td>0.646213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.648100</td>\n",
       "      <td>0.644825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistsic Regression</th>\n",
       "      <td>0.554650</td>\n",
       "      <td>0.585725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.554587</td>\n",
       "      <td>0.581200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Test auc score  Test f1 score\n",
       "Model                                              \n",
       "CatBoost                    0.669888       0.656263\n",
       "XGBoost                     0.669200       0.659600\n",
       "Random Forest               0.663788       0.646213\n",
       "LightGBM                    0.648100       0.644825\n",
       "Logistsic Regression        0.554650       0.585725\n",
       "Decision Tree               0.554587       0.581200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model best results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test auc score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.719</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.607</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistsic Regression</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Test auc score  Test f1 score\n",
       "Model                                              \n",
       "CatBoost                       0.721          0.698\n",
       "XGBoost                        0.719          0.692\n",
       "Random Forest                  0.711          0.683\n",
       "LightGBM                       0.703          0.690\n",
       "Decision Tree                  0.607          0.661\n",
       "Logistsic Regression           0.565          0.598"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat coding results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test auc score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_coding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>сatboost</th>\n",
       "      <td>0.653453</td>\n",
       "      <td>0.641594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>0.639276</td>\n",
       "      <td>0.620448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed</th>\n",
       "      <td>0.637677</td>\n",
       "      <td>0.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.635891</td>\n",
       "      <td>0.618599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leave_one_out</th>\n",
       "      <td>0.567214</td>\n",
       "      <td>0.644219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Test auc score  Test f1 score\n",
       "Cat_coding                                  \n",
       "сatboost             0.653453       0.641594\n",
       "frequency            0.639276       0.620448\n",
       "smoothed             0.637677       0.619995\n",
       "mean                 0.635891       0.618599\n",
       "leave_one_out        0.567214       0.644219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num fill results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test auc score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_fill</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.629075</td>\n",
       "      <td>0.630525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.628658</td>\n",
       "      <td>0.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_frequent</th>\n",
       "      <td>0.624675</td>\n",
       "      <td>0.629983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624400</td>\n",
       "      <td>0.627375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Test auc score  Test f1 score\n",
       "Num_fill                                    \n",
       "mean                 0.629075       0.630525\n",
       "median               0.628658       0.628000\n",
       "most_frequent        0.624675       0.629983\n",
       "0                    0.624400       0.627375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat fill results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test auc score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_fill</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>most_frequent</th>\n",
       "      <td>0.642829</td>\n",
       "      <td>0.623604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No_info</th>\n",
       "      <td>0.625654</td>\n",
       "      <td>0.634604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pad</th>\n",
       "      <td>0.621888</td>\n",
       "      <td>0.627808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bfill</th>\n",
       "      <td>0.616437</td>\n",
       "      <td>0.629867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Test auc score  Test f1 score\n",
       "Cat_fill                                    \n",
       "most_frequent        0.642829       0.623604\n",
       "No_info              0.625654       0.634604\n",
       "pad                  0.621888       0.627808\n",
       "bfill                0.616437       0.629867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('model results')\n",
    "display(result.groupby('Model')['Test auc score','Test f1 score'].mean().sort_values(by=['Test auc score','Test f1 score'],ascending=False))\n",
    "\n",
    "print('model best results')\n",
    "display(result.groupby('Model')['Test auc score','Test f1 score'].max().sort_values(by=['Test auc score','Test f1 score'],ascending=False))\n",
    "\n",
    "print('Cat coding results')\n",
    "display(result.groupby('Cat_coding')['Test auc score','Test f1 score'].mean().sort_values(by=['Test auc score','Test f1 score'],ascending=False))\n",
    "\n",
    "print('Num fill results')\n",
    "display(result.groupby('Num_fill')['Test auc score','Test f1 score'].mean().sort_values(by=['Test auc score','Test f1 score'],ascending=False))\n",
    "\n",
    "print('Cat fill results')\n",
    "display(result.groupby('Cat_fill')['Test auc score','Test f1 score'].mean().sort_values(by=['Test auc score','Test f1 score'],ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты: \n",
    "1. Лучашя дефолтная модель - CatBoost ( Подтвердил слова создателей )\n",
    "2. Лучший способ кодированя - CatBoost\n",
    "3. Лучшее способ заполнения численных пропуском - mean\n",
    "4. Лучшее способ заполнения численных пропуском - most_frequent\n",
    "5. Большая часть деревьев(Decision Tree) переобучалась - ничего удивительного\n",
    "6. Логистическая регрессия показала себя хуже всех\n",
    "7. XGBoost дал почти такой же результат, как и CatBoost - поэтому его и выбираем, его можно сильнее дообучить!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
